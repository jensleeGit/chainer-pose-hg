#!/usr/bin/env python
# -*- coding: utf-8 -*-
 
import cPickle as pickle
from mini_batch_loader_softmax import MiniBatchLoader
from VGGNet import VGGNet
from chainer import serializers
from myfcn import MyFcn
from copy_model import *
from chainer import cuda, optimizers, Variable
import sys
import math
import time
import numpy as np
import scipy.io as sio

TEST_BATCH_SIZE = 1
IMAGE_DIR_PATH  = "data/LSP/images/"

if __name__ == '__main__':

    test_fn = "data/LSP/test_joints.csv"
    test_dl = np.array([l.strip() for l in open(test_fn).readlines()])

    mini_batch_loader = MiniBatchLoader(IMAGE_DIR_PATH, TEST_BATCH_SIZE, MyFcn.IN_SIZE)

    # get model
    myfcn = pickle.load(open('result/myfcn_epoch_10.model', 'rb'))
    myfcn = myfcn.to_gpu()

    sum_accuracy = 0
    sum_loss     = 0
    test_data_size = 1000
    for i in range(0, test_data_size, TEST_BATCH_SIZE):
        raw_x, raw_t = mini_batch_loader.load_data(test_dl[i:i+TEST_BATCH_SIZE])
        x = Variable(cuda.to_gpu(raw_x))
        t = Variable(cuda.to_gpu(raw_t))
        myfcn.train = False
        pred = myfcn(x, t)
        sum_loss     += myfcn.loss.data * TEST_BATCH_SIZE
        #sum_accuracy += myfcn.accuracy * TEST_BATCH_SIZE
        sio.savemat('mat/'+str(i)+'.mat', {'pred':cuda.to_cpu(pred.data)})
 
    print("test mean loss {a}, accuracy {b}".format(a=sum_loss/test_data_size, b=test_data_size))
    sys.stdout.flush()
